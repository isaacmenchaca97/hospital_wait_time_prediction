{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacmenchaca97/hospital_wait_time_prediction/blob/master/data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# Tratamiento de datos\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Gráficos\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Preprocesado y análisis\n",
        "# ==============================================================================\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.tensorflow\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "# Sklearn\n",
        "# ==============================================================================\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# TensorFlow\n",
        "# ==============================================================================\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# from google.colab import data_table\n",
        "# data_table.enable_dataframe_formatter()\n",
        "template_style = \"plotly_dark\"\n",
        "\n",
        "import joblib\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!wget https://github.com/isaacmenchaca97/hospital_wait_time_prediction/releases/download/v1.0.0/ARTICLE.tar.gz\n",
        "# !wget https://github.com/isaacmenchaca97/hospital_wait_time_prediction/releases/download/v1.0.0/EDIESCA.tar.gz\n",
        "\n",
        "#!tar -xzvf ARTICLE.tar.gz\n",
        "# !tar -xzvf EDIESCA.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select target and features\n",
        "df_analisys = pd.read_csv('../data/processed/EDIESCA.csv')\n",
        "X = df_analisys.drop(columns=['tiempo_total'])\n",
        "y = df_analisys['tiempo_total']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on CPU\n"
          ]
        }
      ],
      "source": [
        "# Check if TPU is available\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # No need to specify TPU address if on Colab\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  print(\"Running on TPU\")\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "except ValueError: # If TPU is not found, use default strategy\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    print(\"Running on CPU\")\n",
        "  else:\n",
        "    print(\"Running on GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pXAkendNNrN"
      },
      "source": [
        "# Analisys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV3HqJYsNNrN"
      },
      "source": [
        "##### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uPIypiHqNNrQ"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'date'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/Documents/hospital_wait_time_prediction/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_analisys\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFecha\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m df_analisys[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_analisys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtime\n\u001b[1;32m      4\u001b[0m df_analisys[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_timedelta(df_analisys\u001b[38;5;241m.\u001b[39mentry_time\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))\n\u001b[1;32m      7\u001b[0m df_analisys\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiempo_total\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaiting_time\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/Documents/hospital_wait_time_prediction/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/Documents/hospital_wait_time_prediction/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ],
      "source": [
        "df_analisys.rename(columns={'Fecha':'date'}, inplace=True)\n",
        "\n",
        "df_analisys['entry_time'] = df_analisys['date'].dt.time\n",
        "df_analisys['entry_time'] = pd.to_timedelta(df_analisys.entry_time.astype(str))\n",
        "\n",
        "\n",
        "df_analisys.rename(columns={'tiempo_total':'waiting_time'}, inplace=True)\n",
        "df_analisys['waiting_time'] = pd.to_timedelta(df_analisys['waiting_time'], unit='m')\n",
        "\n",
        "df_analisys['completion_time'] = df_analisys['waiting_time'] + df_analisys['entry_time']\n",
        "\n",
        "df_analisys['waiting_ber_munets'] = df_analisys.waiting_time.dt.seconds / 60\n",
        "df_analisys['waiting_ber_munets'] = df_analisys['waiting_ber_munets'].round(0)\n",
        "\n",
        "df_analisys['weekday'] = df_analisys.date.dt.strftime('%A')                      # new column for extract 'weekday' from 'date'\n",
        "df_analisys['hours'] = df_analisys.entry_time.dt.components.hours                # new column for extract the  'hours' from 'entry_time'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Yip5orNNrQ"
      },
      "outputs": [],
      "source": [
        "df_analisys.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z91lJ3tNNrj"
      },
      "outputs": [],
      "source": [
        "df_analisys.drop(columns=['nombre', 'genero', 'Dx'], inplace=True)\n",
        "df_analisys.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbxveqUjNNrj"
      },
      "source": [
        "##### Patient heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Q-dZf6NNrk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def grouped_data2(column_name):\n",
        "    if column_name == 'completion_time':\n",
        "        answer = pd.pivot_table(df_analisys, index='hours', columns=['weekday'], aggfunc='count')\n",
        "    elif column_name == 'waiting_ber_munets':\n",
        "        answer = pd.pivot_table(df_analisys, index='hours',\n",
        "                                columns=['weekday'] , aggfunc='mean').round(1)\n",
        "    else:\n",
        "        return(column_name + \" is not in the columns\")\n",
        "\n",
        "    answer = answer[column_name]\n",
        "    answer = answer.fillna(0)\n",
        "    answer = answer[['Sunday', 'Monday', 'Tuesday',\n",
        "                  'Wednesday', 'Thursday',\n",
        "                  'Friday', 'Saturday']]\n",
        "    return answer\n",
        "answer3 =  grouped_data2('completion_time')\n",
        "answer4 =  grouped_data2('waiting_ber_munets')\n",
        "print(answer3,answer4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB7kUWE-NNrk"
      },
      "outputs": [],
      "source": [
        "fig3 = px.imshow(answer3,\n",
        "                labels=dict(x=\"weekday\", y=\"hours\", color=\"number of paitant\") ,\n",
        "                aspect=\"auto\", color_continuous_scale='tempo',\n",
        "                template = template_style,\n",
        "                text_auto=True, width=900, height=900)\n",
        "fig3.update_xaxes(side=\"top\")\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gw7NbvANNrl"
      },
      "source": [
        "##### Hour heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC0bDYOgNNrl"
      },
      "outputs": [],
      "source": [
        "fig4 = px.imshow(answer4,\n",
        "                labels=dict(x=\"weekday\", y=\"hours\",\n",
        "                            color=\"the waiting time per min\") ,\n",
        "                            aspect=\"auto\", color_continuous_scale='tempo',\n",
        "                            template = template_style,\n",
        "                            text_auto=True, width=900, height=900)\n",
        "fig4.update_xaxes(side=\"top\")\n",
        "fig4.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmZwKTwENNrm"
      },
      "source": [
        "##### Bar chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO4ogTeTNNrm"
      },
      "outputs": [],
      "source": [
        "def grouped_data(column_name):\n",
        "    '''\n",
        "    Groupby column and return DataFrame\n",
        "    Input: Column Name\n",
        "    '''\n",
        "    df_tmp = df_analisys.groupby(column_name)[['waiting_ber_munets']].mean().round(0)\n",
        "    df_tmp2 = df_analisys[column_name].value_counts()      #this for concat\n",
        "\n",
        "    pivot_f = pd.concat([df_tmp, df_tmp2.rename('number_of_patient')],axis=1)\n",
        "    pivot_f.reset_index(inplace=True)\n",
        "    pivot_f = pivot_f.rename(columns={'index': column_name })\n",
        "    return pivot_f\n",
        "\n",
        "answer5 = grouped_data('hours')\n",
        "link_size = [3,6]\n",
        "fig = px.bar(x=answer5['hours'],\n",
        "             y=answer5['waiting_ber_munets'],\n",
        "             template= template_style,\n",
        "             text_auto='.2s',\n",
        "             labels={'x':'the hour',\n",
        "                     'y':'the waiting time per m'}\n",
        "             ).add_traces(\n",
        "      px.line(answer5, x=answer5['hours'], text='number_of_patient',\n",
        "             y=answer5['number_of_patient'],markers=True).update_traces(yaxis=\"y2\",\n",
        "             showlegend=True, line=dict(color = 'red', width=link_size[1]), name=\"number_of_patient\").data)\n",
        "fig.update_layout(yaxis2={\"side\":\"right\", \"overlaying\":\"y\"})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVYRgOB9NNrn"
      },
      "source": [
        "##### Weekly chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXCaKShoNNro"
      },
      "outputs": [],
      "source": [
        "answer2 =  grouped_data('weekday')\n",
        "# Create Chart for the Daily\n",
        "fig2 = px.bar(answer2,\n",
        "             x='weekday',\n",
        "             y='number_of_patient',\n",
        "             color='waiting_ber_munets',\n",
        "             labels={'waiting_ber_munets':'the waiting time per m'} ,\n",
        "             color_continuous_scale=['green','yellow','red'],\n",
        "             template = template_style,\n",
        "             title = '<b>Daily visualization</b>')\n",
        "# Display Plot\n",
        "fig2.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
