{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "sm_autoscaling_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# S3 locations used for parameterizing the notebook run\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\"\n",
    "model_prefix = \"models/xgb-fraud\"\n",
    "\n",
    "data_capture_key = f\"{write_prefix}/data-capture\"\n",
    "\n",
    "# S3 location of trained model artifact\n",
    "model_uri = f\"s3://{read_bucket}/{model_prefix}/fraud-det-xgb-model.tar.gz\"\n",
    "\n",
    "# S3 path where data captured at endpoint will be stored\n",
    "data_capture_uri = f\"s3://{write_bucket}/{data_capture_key}\"\n",
    "\n",
    "# S3 location of test data\n",
    "test_data_uri = f\"s3://{read_bucket}/{read_prefix}/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the SageMaker managed XGBoost image\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# Specify a unique model name that does not exist\n",
    "model_name = \"fraud-detect-xgb\"\n",
    "primary_container = {\"Image\": training_image, \"ModelDataUrl\": model_uri}\n",
    "\n",
    "model_matches = sm_client.list_models(NameContains=model_name)[\"Models\"]\n",
    "if not model_matches:\n",
    "    model = sm_client.create_model(\n",
    "        ModelName=model_name, PrimaryContainer=primary_container, ExecutionRoleArn=sagemaker_role\n",
    "    )\n",
    "else:\n",
    "    print(f\"Model with name {model_name} already exists! Change model name to create new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Config name\n",
    "endpoint_config_name = f\"{model_name}-endpoint-config\"\n",
    "\n",
    "# Endpoint config parameters\n",
    "production_variant_dict = {\n",
    "    \"VariantName\": \"Alltraffic\",\n",
    "    \"ModelName\": model_name,\n",
    "    \"InitialInstanceCount\": 1,\n",
    "    \"InstanceType\": \"ml.m5.xlarge\",\n",
    "    \"InitialVariantWeight\": 1,\n",
    "}\n",
    "\n",
    "# Data capture config parameters\n",
    "data_capture_config_dict = {\n",
    "    \"EnableCapture\": True,\n",
    "    \"InitialSamplingPercentage\": 100,\n",
    "    \"DestinationS3Uri\": data_capture_uri,\n",
    "    \"CaptureOptions\": [{\"CaptureMode\": \"Input\"}, {\"CaptureMode\": \"Output\"}],\n",
    "}\n",
    "\n",
    "\n",
    "# Create endpoint config if one with the same name does not exist\n",
    "endpoint_config_matches = sm_client.list_endpoint_configs(NameContains=endpoint_config_name)[\n",
    "    \"EndpointConfigs\"\n",
    "]\n",
    "if not endpoint_config_matches:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[production_variant_dict],\n",
    "        DataCaptureConfig=data_capture_config_dict,\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"Endpoint config with name {endpoint_config_name} already exists! Change endpoint config name to create new\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_matches = sm_client.list_endpoints(NameContains=endpoint_name)[\"Endpoints\"]\n",
    "if not endpoint_matches:\n",
    "    endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "    )\n",
    "else:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists! Change endpoint name to create new\")\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Endpoint Status: {status}...\")\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch test data to run predictions with the endpoint\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "\n",
    "# For content type text/csv, payload should be a string with commas separating the values for each feature\n",
    "# This is the inference request serialization step\n",
    "# CSV serialization\n",
    "csv_file = io.StringIO()\n",
    "test_sample = test_df.drop([\"fraud\"], axis=1).iloc[:5]\n",
    "test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "response = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, Body=payload, ContentType=\"text/csv\", Accept=\"text/csv\"\n",
    ")\n",
    "\n",
    "# This is the inference response deserialization step\n",
    "# This is a bytes object\n",
    "result = response[\"Body\"].read()\n",
    "# Decoding bytes to a string\n",
    "result = result.decode(\"utf-8\")\n",
    "# Converting to list of predictions\n",
    "result = re.split(\",|\\n\", result)\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df[\"Prediction\"] = result[:5]\n",
    "prediction_df[\"Label\"] = test_df[\"fraud\"].iloc[:5].values\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(90):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "print()\n",
    "print(f\"Found {len(capture_files)} Data Capture Files:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "capture_file = S3Downloader.read_file(capture_files[0]).split(\"\\n\")\n",
    "capture_record = json.loads(capture_file[0])\n",
    "capture_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = capture_record[\"captureData\"][\"endpointInput\"][\"data\"]\n",
    "output_data = capture_record[\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "input_data_list = base64.b64decode(input_data).decode(\"utf-8\").split(\"\\n\")\n",
    "print(input_data_list)\n",
    "output_data_list = base64.b64decode(output_data).decode(\"utf-8\").split(\"\\n\")\n",
    "print(output_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# SageMaker expects resource id to be provided with the following structure\n",
    "resource_id = f\"endpoint/{endpoint_name}/variant/{resp['ProductionVariants'][0]['VariantName']}\"\n",
    "\n",
    "# Scaling configuration\n",
    "scaling_config_response = sm_autoscaling_client.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scaling Policy\n",
    "policy_name = f\"scaling-policy-{endpoint_name}\"\n",
    "scaling_policy_response = sm_autoscaling_client.put_scaling_policy(\n",
    "    PolicyName=policy_name,\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 5.0,  # Target for avg invocations per minutes\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\",\n",
    "        },\n",
    "        \"ScaleInCooldown\": 600,  # Duration in seconds until scale in\n",
    "        \"ScaleOutCooldown\": 60,  # Duration in seconds between scale out\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_autoscaling_client.describe_scaling_policies(ServiceNamespace=\"sagemaker\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "for i in response[\"ScalingPolicies\"]:\n",
    "    pp.pprint(i[\"PolicyName\"])\n",
    "    print(\"\")\n",
    "    if \"TargetTrackingScalingPolicyConfiguration\" in i:\n",
    "        pp.pprint(i[\"TargetTrackingScalingPolicyConfiguration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Endpoint will be tested for {request_duration} seconds\")\n",
    "while time.time() < end_time:\n",
    "    csv_file = io.StringIO()\n",
    "    test_sample = test_df.drop([\"fraud\"], axis=1).iloc[[np.random.randint(0, test_df.shape[0])]]\n",
    "    test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "    payload = csv_file.getvalue()\n",
    "    response = sm_runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, Body=payload, ContentType=\"text/csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the instance counts after the endpoint gets more load\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = response[\"EndpointStatus\"]\n",
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(\n",
    "    f\"Waiting for Instance count increase for a max of {request_duration} seconds. Please re run this cell in case the count does not change\"\n",
    ")\n",
    "while time.time() < end_time:\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = response[\"EndpointStatus\"]\n",
    "    instance_count = response[\"ProductionVariants\"][0][\"CurrentInstanceCount\"]\n",
    "    print(f\"Status: {endpoint_status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")\n",
    "    if (endpoint_status == \"InService\") and (instance_count > 1):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "\n",
    "# Delete endpoint configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete endpoint\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
