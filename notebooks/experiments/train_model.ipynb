{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner, IntegerParameter\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# Setting SageMaker variables\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\"\n",
    "\n",
    "\n",
    "# Setting S3 location for read and write operations\n",
    "train_data_key = f\"{read_prefix}/train.csv\"\n",
    "test_data_key = f\"{read_prefix}/test.csv\"\n",
    "validation_data_key = f\"{read_prefix}/validation.csv\"\n",
    "model_key = f\"{write_prefix}/model\"\n",
    "output_key = f\"{write_prefix}/output\"\n",
    "\n",
    "\n",
    "train_data_uri = f\"s3://{read_bucket}/{train_data_key}\"\n",
    "test_data_uri = f\"s3://{read_bucket}/{test_data_key}\"\n",
    "validation_data_uri = f\"s3://{read_bucket}/{validation_data_key}\"\n",
    "model_uri = f\"s3://{write_bucket}/{model_key}\"\n",
    "output_uri = f\"s3://{write_bucket}/{output_key}\"\n",
    "estimator_output_uri = f\"s3://{write_bucket}/{write_prefix}/training_jobs\"\n",
    "bias_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify-output/bias\"\n",
    "explainability_report_output_uri = (\n",
    "    f\"s3://{write_bucket}/{write_prefix}/clarify-output/explainability\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name_prefix = \"xgbtune\"\n",
    "training_job_name_prefix = \"xgbtrain\"\n",
    "\n",
    "xgb_model_name = \"fraud-detect-xgb-model\"\n",
    "endpoint_name_prefix = \"xgb-fraud-model-dev\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.m4.xlarge\"\n",
    "clarify_instance_count = 1\n",
    "clarify_instance_type = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile xgboost_train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters and algorithm parameters are described here\n",
    "    parser.add_argument(\"--num_round\", type=int, default=100)\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=3)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.9)\n",
    "    parser.add_argument(\"--colsample_bytree\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--eval_metric\", type=str, default=\"auc\")\n",
    "    parser.add_argument(\"--nfold\", type=int, default=3)\n",
    "    parser.add_argument(\"--early_stopping_rounds\", type=int, default=3)\n",
    "    \n",
    "\n",
    "    # SageMaker specific arguments. Defaults are set in the environment variables\n",
    "    # Location of input training data\n",
    "    parser.add_argument(\"--train_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    # Location of input validation data\n",
    "    parser.add_argument(\"--validation_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    # Location where trained model will be stored. Default set by SageMaker, /opt/ml/model\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    # Location where model artifacts will be stored. Default set by SageMaker, /opt/ml/output/data\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    data_train = pd.read_csv(f\"{args.train_data_dir}/train.csv\")\n",
    "    train = data_train.drop(\"fraud\", axis=1)\n",
    "    label_train = pd.DataFrame(data_train[\"fraud\"])\n",
    "    dtrain = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    \n",
    "    data_validation = pd.read_csv(f\"{args.validation_data_dir}/validation.csv\")\n",
    "    validation = data_validation.drop(\"fraud\", axis=1)\n",
    "    label_validation = pd.DataFrame(data_validation[\"fraud\"])\n",
    "    dvalidation = xgb.DMatrix(validation, label=label_validation)\n",
    "\n",
    "    params = {\"max_depth\": args.max_depth,\n",
    "              \"eta\": args.eta,\n",
    "              \"objective\": args.objective,\n",
    "              \"subsample\" : args.subsample,\n",
    "              \"colsample_bytree\":args.colsample_bytree\n",
    "             }\n",
    "    \n",
    "    num_boost_round = args.num_round\n",
    "    nfold = args.nfold\n",
    "    early_stopping_rounds = args.early_stopping_rounds\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        metrics=[\"auc\"],\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=len(cv_results))\n",
    "    \n",
    "    train_pred = model.predict(dtrain)\n",
    "    validation_pred = model.predict(dvalidation)\n",
    "    \n",
    "    train_auc = roc_auc_score(label_train, train_pred)\n",
    "    validation_auc = roc_auc_score(label_validation, validation_pred)\n",
    "    \n",
    "    print(f\"[0]#011train-auc:{train_auc:.2f}\")\n",
    "    print(f\"[0]#011validation-auc:{validation_auc:.2f}\")\n",
    "\n",
    "    metrics_data = {\"hyperparameters\" : params,\n",
    "                    \"binary_classification_metrics\": {\"validation:auc\": {\"value\": validation_auc},\n",
    "                                                      \"train:auc\": {\"value\": train_auc}\n",
    "                                                     }\n",
    "                   }\n",
    "              \n",
    "    # Save the evaluation metrics to the location specified by output_data_dir\n",
    "    metrics_location = args.output_data_dir + \"/metrics.json\"\n",
    "    \n",
    "    # Save the model to the location specified by model_dir\n",
    "    model_location = args.model_dir + \"/xgboost-model\"\n",
    "\n",
    "    with open(metrics_location, \"w\") as f:\n",
    "        json.dump(metrics_data, f)\n",
    "\n",
    "    with open(model_location, \"wb\") as f:\n",
    "        joblib.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker estimator\n",
    "\n",
    "# Set static hyperparameters that will not be tuned\n",
    "static_hyperparams = {\"eval_metric\": \"auc\", \"objective\": \"binary:logistic\", \"num_round\": \"5\"}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"xgboost_train.py\",\n",
    "    output_path=estimator_output_uri,\n",
    "    code_location=estimator_output_uri,\n",
    "    hyperparameters=static_hyperparams,\n",
    "    role=sagemaker_role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    framework_version=\"1.3-1\",\n",
    "    base_job_name=training_job_name_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting ranges of hyperparameters to be tuned\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"subsample\": ContinuousParameter(0.7, 0.95),\n",
    "    \"colsample_bytree\": ContinuousParameter(0.7, 0.95),\n",
    "    \"max_depth\": IntegerParameter(1, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "# Setting up tuner object\n",
    "tuner_config_dict = {\n",
    "    \"estimator\": xgb_estimator,\n",
    "    \"max_jobs\": 5,\n",
    "    \"max_parallel_jobs\": 2,\n",
    "    \"objective_metric_name\": objective_metric_name,\n",
    "    \"hyperparameter_ranges\": hyperparameter_ranges,\n",
    "    \"base_tuning_job_name\": tuning_job_name_prefix,\n",
    "    \"strategy\": \"Random\",\n",
    "}\n",
    "tuner = HyperparameterTuner(**tuner_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the input channels for tuning job\n",
    "s3_input_train = TrainingInput(\n",
    "    s3_data=\"s3://{}/{}\".format(read_bucket, train_data_key),\n",
    "    content_type=\"csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "s3_input_validation = TrainingInput(\n",
    "    s3_data=\"s3://{}/{}\".format(read_bucket, validation_data_key),\n",
    "    content_type=\"csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "tuner.fit(\n",
    "    inputs={\"train\": s3_input_train, \"validation\": s3_input_validation}, include_cls_metadata=False\n",
    ")\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of tuning results ordered in descending order of performance\n",
    "df_tuner = sagemaker.HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.job_name).dataframe()\n",
    "df_tuner = df_tuner[df_tuner[\"FinalObjectiveValue\"] > -float(\"inf\")].sort_values(\n",
    "    \"FinalObjectiveValue\", ascending=False\n",
    ")\n",
    "df_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model for biases and explain model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_job_info = sagemaker_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")\n",
    "\n",
    "model_matches = sagemaker_client.list_models(NameContains=xgb_model_name)[\"Models\"]\n",
    "\n",
    "if not model_matches:\n",
    "    _ = sess.create_model_from_job(\n",
    "        name=xgb_model_name,\n",
    "        training_job_name=tuner_job_info[\"BestTrainingJob\"][\"TrainingJobName\"],\n",
    "        role=sagemaker_role,\n",
    "        image_uri=tuner_job_info[\"TrainingJobDefinition\"][\"AlgorithmSpecification\"][\n",
    "            \"TrainingImage\"\n",
    "        ],\n",
    "    )\n",
    "else:\n",
    "    print(f\"Model {xgb_model_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_uri)\n",
    "train_df_cols = train_df.columns.to_list()\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=clarify_instance_count,\n",
    "    instance_type=clarify_instance_type,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# Data config\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_uri,\n",
    "    s3_output_path=bias_report_output_uri,\n",
    "    label=\"fraud\",\n",
    "    headers=train_df_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# Model config\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_model_name,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# Model predictions config to get binary labels from probabilities\n",
    "predictions_config = sagemaker.clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "# Bias config\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name=\"customer_gender_female\",\n",
    "    facet_values_or_threshold=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=[\"CI\"],\n",
    "    post_training_methods=[\"DPPL\"],\n",
    ")\n",
    "\n",
    "clarify_bias_job_name = clarify_processor.latest_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy bias report and view locally\n",
    "!aws s3 cp s3://{write_bucket}/{write_prefix}/clarify-output/bias/report.pdf ./clarify_bias_output.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_uri,\n",
    "    s3_output_path=explainability_report_output_uri,\n",
    "    label=\"fraud\",\n",
    "    headers=train_df_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "# Use mean of train dataset as baseline data point\n",
    "shap_baseline = [list(train_df.drop([\"fraud\"], axis=1).mean())]\n",
    "\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=500,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True,\n",
    ")\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy explainability report and view\n",
    "!aws s3 cp s3://{write_bucket}/{write_prefix}/clarify-output/explainability/report.pdf ./clarify_explainability_output.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "local_explanations_out = pd.read_csv(\n",
    "    explainability_report_output_uri + \"/explanations_shap/out.csv\"\n",
    ")\n",
    "feature_names = [str.replace(c, \"_label0\", \"\") for c in local_explanations_out.columns.to_series()]\n",
    "local_explanations_out.columns = feature_names\n",
    "\n",
    "selected_example = 100\n",
    "print(\"Example number:\", selected_example)\n",
    "\n",
    "local_explanations_out.iloc[selected_example].plot(\n",
    "    kind=\"bar\",\n",
    "    title=\"Local explanation for the example number \" + str(selected_example),\n",
    "    rot=60,\n",
    "    figsize=(20, 8),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model to a real-time inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_job_name = tuner.best_training_job()\n",
    "\n",
    "model_path = estimator_output_uri + \"/\" + best_train_job_name + \"/output/model.tar.gz\"\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "create_model_config = {\n",
    "    \"model_data\": model_path,\n",
    "    \"role\": sagemaker_role,\n",
    "    \"image_uri\": training_image,\n",
    "    \"name\": endpoint_name_prefix,\n",
    "    \"predictor_cls\": sagemaker.predictor.Predictor,\n",
    "}\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.model.Model(**create_model_config)\n",
    "\n",
    "# Deploy the best model and get access to a SageMaker Predictor\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=predictor_instance_count,\n",
    "    instance_type=predictor_instance_type,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=CSVDeserializer(),\n",
    ")\n",
    "print(f\"\\nModel deployed at endpoint : {model.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test data\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "payload = test_df.drop([\"fraud\"], axis=1).iloc[0].to_list()\n",
    "print(\n",
    "    f\"Model predicted score : {float(predictor.predict(payload)[0][0]):.3f}, True label : {test_df['fraud'].iloc[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "try:\n",
    "    sess.delete_model(xgb_model_name)\n",
    "except Exception:\n",
    "    pass\n",
    "sess.delete_model(model.name)\n",
    "\n",
    "# Delete inference endpoint config\n",
    "sess.delete_endpoint_config(endpoint_config_name=predictor._get_endpoint_config_name())\n",
    "\n",
    "# Delete inference endpoint\n",
    "sess.delete_endpoint(endpoint_name=model.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
